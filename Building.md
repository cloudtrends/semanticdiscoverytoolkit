

# Introduction #

The toolkit can be built using any of the following methods:

  * Download and install module jars (with dependencies)
  * Check out from the repository and build
  * Create and maintain a snapshot

# Details #

## Downloading Module Jars ##

Any of the module jars (along with their internal dependencies) can be downloaded, placed on your classpath, and used.

In addition to the project jars, you will also need (some or all of) the 3rd party library jars on which the modules depend. You will find copies of these libraries in the repository's trunk/lib directory.

The module jars are named using the convention sd-_module_._date_.jar

The internal dependencies between modules are as follows:

| Module | Description | Dependencies |
|:-------|:------------|:-------------|
| io     | Independent input/output utilities | _no dependencies_ |
| util   | Simple utilities and algorithm implementations | io           |
| xml    | Utilities for working with xml | io, util     |
| nlp    | Base natural language processing utilities | io, util, xml |
| cio    | Complex input/output utilities | io, util, xml |
| bdb    | Berkeley DB wrapper utilities | io, util, cio |
| text   | Complex text-based utilities and algorithm implementations | io, util, xml, nlp, cio, bdb |
| cluster | Parallel distributed processing framework | io, util, xml, cio, bdb, text |
| extract | Information extraction and classification frameworks | io, util, xml, nlp, cio, text |
| lang   | Natural language wrappers and utilities | io, util, xml, nlp, cio, bdb, text |
| crawl  | Web crawling utilities | io, util, xml, nlp, cio, bdb, text |

For convenience, the "base" module (sd-base._date_.jar) is the combination of all of the base modules: io, util, xml, nlp, cio, bdb, and text

The "advanced" modules are cluster, extract, lang, and crawl. To use just one advanced module, it is simplest to download the "base" jar and the advanced module's jar (along with external libs).

To use all of the modules, download the "base" jar and all of the advanced module jars (along with external libs).

Refer to [Modules](http://code.google.com/p/semanticdiscoverytoolkit/wiki/Modules) and [Documentation](http://code.google.com/p/semanticdiscoverytoolkit/wiki/Documentation) for more information about the modules.


## Checking Out and Building from the Repository ##

See this project's "Source" tab's Checkout link for how to check out the code. Then, follow the instructions below to build it.

### Building from Source ###

Build the sourcecode using java 1.6+ and ant (currently using 1.7.1) with the build.xml file under semanticdiscoverytoolkit: "ant all"

**Note**: These build instructions assume a bash shell under the Linux operating system. It is currently left to you to make appropriate adjustments if necessary.

The following environment settings are required to successfully build and run all tests:

```
  % export JAVA_HOME=<path-to-java>
  % export ANT_HOME=<path-to-ant>
  % export PATH=.:$JAVA_HOME/bin:$ANT_HOME/bin:$PATH;
  % export JAVA_OPTS="-Xmx640m -Dcom.sun.management.jmxremote"
  % export ANT_OPTS=-Xmx500m
```

To run the cluster tests, you will need non-interactive ssh capability to your own user@localhost. If you cannot execute "ssh localhost pwd" without input prompts, then you do not have the necessary non-interactive setup. You can setup your environment by doing the following:

```
  % cd ~/.ssh
  % ssh-keygen
  % cat id_rsa.pub >> authorized_keys
```

**Note**: If you already have ssh keys (an id\_rsa.pub or id\_dsa.pub file in your .ssh folder, all that is needed is to append the public key to your .ssh/authorized\_keys file. If you don't have ssh keys, then when you run ssh-keygen, accepting all ssh-keygen defaults by repeatedly hitting the enter key oughtta do it!

The "all" target to the ant build will build all of the jars, generate javadocs, and run unit tests.


## Creating and Maintaining a Snapshot ##

The project can generate a clean source tarball named "sd-toolkit.src._date_.tgz" that is a self-sustaining instance of the project divorced from subversion. The snapshot is generated by running ant at the top level with the target "fullsource."

Be aware that changes made to a snapshot are not naturally merged with the ongoing project. That being noted, a snapshot can prove useful in cases where a recoverable state is required.

To recreate the project from a snapshot tarball, unpack the tarball using the command "tar -xzf sd-toolkit.src._date_.tgz" and follow the build instructions above.